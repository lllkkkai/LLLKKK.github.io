---
layout: post
category: Java
---

## 数据结构
HashMap由数组+链表实现对数据的存储，JDK1.8中链表长度大于8转换为红黑树.

- 为什么使用红黑树替换链表？
> 随着存储数据的增加，链表的长度会持续增长，查询效率会越来越低，通过转变成红黑树可以提升查询的效率
> 
> 红黑树增删改查**时间复杂度都是O(logn)** 比链表好

HashMap中的<key, value>元素被封装成Node对象存储
```Java
static class Node<K,V> implements Map.Entry<K,V> {
    final int hash;
    final K key;
    V value;
    Node<K,V> next;

    Node(int hash, K key, V value, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.value = value;
        this.next = next;
    }

    public final K getKey()        { return key; }
    public final V getValue()      { return value; }
    public final String toString() { return key + "=" + value; }

    public final int hashCode() {
        return Objects.hashCode(key) ^ Objects.hashCode(value);
    }

    public final V setValue(V newValue) {
        V oldValue = value;
        value = newValue;
        return oldValue;
    }
}
```

## put值做了什么
判断map是否为空，为空调用resize函数进行初始化，初始数组大小为16(数组大小一定是2的幂次方），初始加载因子0.75，之后进行hash映射计算(n-1)&hash，得到hash位置(数组中的位置)如果没有hash冲突，就直接插入。之后分两种情况讨论，红黑树结构，按照红黑树的方式进行插入或覆盖。链表结构，使用尾插法进行插入或替换，并且如果插入后，超过规定的阈值，链表结构会转换成红黑树结构。

## 1.8下的扩容
hashmap的长度是2的n次幂，因为计算节点下标时，可以满足 hash%n == (n-1)&hash，利用位运算加快计算速度并且实现更少的hash碰撞

**扩容条件**：存储的数量大于阈值，

**源码解析**：
1. 在resize()方法中，定义了oldCap参数，记录了原table的长度，定义了newCap参数，记录新table长度，newCap是oldCap长度的2倍（注释1），同时扩展点也乘2。

2. 注释2是循环原table，把原table中的每个链表中的每个元素放入新table。

3. 注释3，e.next==null，指的是链表中只有一个元素，所以直接把e放入新table，其中的e.hash & (newCap - 1)就是计算e在新table中的位置，和JDK1.7中的indexFor()方法是一回事。

4. 注释// preserve order，这个注释是源码自带的，这里定义了4个变量：loHead，loTail，hiHead，hiTail，看起来可能有点眼晕，其实这里体现了JDK1.8对于计算节点在table中下标的新思路：

> 正常情况下，计算节点在table中的下标的方法是：hash&(oldTable.length-1)，扩容之后，table长度翻倍，计算table下标的方法是hash&(newTable.length-1)，也就是hash&(oldTable.length*2-1)，于是我们有了这样的结论：这新旧两次计算下标的结果，要不然就相同，要不然就是新下标等于旧下标加上旧数组的长度。